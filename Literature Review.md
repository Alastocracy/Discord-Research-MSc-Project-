**Initial Research**
The idea for this project came from Discords own transparency report (2021) for the second half of 2020. The report highlighted a startling number of accounts banned and servers shut down, but also showed a dramatic increase of over 50% of reports received. Additionally, looking at the statistics posted on the removed servers the majority of 27,410 removed were removed for Cybercrime or Exploitative Content. Along with statistics on extremism, harassment and distribution of malware and other cyber-attacks also included in the report paints a picture of a rapidly growing platform plagued by security and safety issues.

This led to investigating what academic research had been done around Discord, and the search turned up very little. What there is focused on a couple of areas: Digital Forensics, and Community Building. While both of these areas are of some interest, the lack of research into any of the areas the transparency report highlighted was surprising. In contrast, looking at other instant messaging or even social media applications (which are admittedly much bigger platforms, though Discord is growing) and there has been significant research done into safety, harassment, privacy and a multitude of adjacent areas. Similarly, there has been research into other VoIP programs but much of this is older and somewhat outdated; though the principles could still be relevant. Much of the recent research into VoIP technologies has been concerning its use for online meetings and activities, especially during the COVID-19 Pandemic when businesses that were able to had many remote workers and students cannot physically attend classes or lectures (Pratama et al. 2020).

**Existing Research**
*Digital Forensics*
When investigating academic research on Discord, the first area of interest that appeared prevalent was digital forensics and how data retrieved from Discord can be used as evidence in a court of law. In the transparency report mentioned earlier Discord shows the number of servers they have taken down regarding Cybercrime and additionally reports they have sent to the NCMEC (National Center for Missing and Exploited Children). Crime is evidently occurring on the platform or being organised on the platform via the use of text channels in servers or direct messages between users, and these messages can be retrieved and used as evidence. There are channels to retrieve information from the company itself either by emergency request in the USA or Mutual Legal Assistance Treaty process internationally, but it is also possible to retrieve information directly from a suspect computer or mobile device. 

In 2020 Motylinkski et al. noted the rise of Cybercrime on Discord and created DiscFor, a tool for retrieving Discord data and analysing it. In their report they find that even without access to an individual’s account, they can retrieve recent messages and other data from cache memory. This data is cleared every 30 days however, and it is possible for a user to manually clear their cache. They recognise the importance of tools like this as the platform is quickly growing to become a preferred platform for organising cybercrime, and while Discord is constantly shutting down servers creating new ones is trivial. 

Follow up research by the same group of researchers resulted in the publication of ‘Discord Server Forensics: Analysis and Extraction of Digital Evidence’ (Motylinkski et al. 2021). In it they note the continued growth of cybercrime on the platform, not only being organised in Discord servers but also perpetrated via the platform. They highlight statistics from Discord’s 2019 transparency report, on how popular the platform is becoming as a home for cybercriminals and point to YouTube where many users have made videos about malicious encounters they have experienced on the platform. The focus of this paper is similar to its predecessor, on what can be recovered from the Discord application in terms of forensic evidence but many of the points are applicable. The suggestion is that the types of crime popular on the platform such as data theft, selling personal information, spreading malware and similar are made easier by the level of anonymity you can have in user created private or semi-private servers.

Moffitt et al. 2021 discuss how there has been significant research into digital forensics on other VoIP (Voice over Internet Protocol) applications like Skype and WhatsApp while Discord has barely had its surface scratched. The focus of this paper is once more on what can be extracted from the application, but it also investigates how Discord protects its user’s data and point out privacy and security concerns. The research undertaken finds that Discords log files make users vulnerable and that a hostile actor gaining access to them would find significant private data (though this is useful from a forensics standpoint). The conclusion also highlights that messages sent over Discord are logged in plaintext and this should be concerning to users. The (albeit) limited discussion in this paper of user’s privacy concerns and how well Discord is protecting their data draws attention to the fact that while there is acknowledgement of cybercrime being perpetrated via the Discord platform, research hasn’t been conducted into the user side of this; their experiences and concerns. The largest reference to user experience was through YouTube videos made from experiences that are hard to verify and trust completely. 

*Community Building*
The other major topic area of research on Discord, is how it can be used as a platform for building communities; with the primary focus on using Discord for education. In 2020 and 2021 we had the year of online learning, where classes and lectures were forced to move online through technologies like MS teams or Zoom calls. This led to research being done on using a Discord server as a hub for a learning community, where students can discuss topics, learn together and help each other. Prior to the necessity for online learning though, some research had been done into the merits of Discord for learning communities.

In 2019 the University of Alaska Anchorage published a paper discussing their experience using the platform for online tutoring (Mock, 2019). They found that engagement and uptake via Discord was much higher than other online platforms they had tried, and that its use expanded from tutoring to social gatherings and other group activities. This shines a light on how communities on Discord can be incredibly useful and positive. The platform was designed with Gaming in mind, but has developed into a space for anything the user would like to host. We’ve seen the negative side of this with servers for cybercrime and hacking discussed earlier, and this shows the other end of the spectrum.

Once it was clear that education would have to be moved online for a time, more research was done into different platforms use to facilitate online learning. Vladoiu and Constantinescu (2020) discuss transitioned from in-person to online learning on Discord and the lessons they learnt building a community on the platform.  One key feature they implemented was a bot (programable entity within Discords infrastructure that can be added to a server) to track attendance and help connect the Discord learning to external online resources. Bots are a very useful tool that servers can make use of for different roles such as filtering messages or playing music, but in this case, it is being used to make resources more accessible. When assessing their research, one of the major findings was that over 95% of students found using the Discord community made them feel more involved with each other and the work; though they were still unhappy about not being able to meet in person. Problems were also discussed, with additional distractions and worse overall attendance as there was less accountability for missing online classes. This lack of accountability is a larger problem overall on Discord, but is mitigated here by the fact that all of the community members are registered to the university and can be held accountable somewhat, even if it is to a lesser degree. In other communities with much less accountability this could lead to increases in malicious behaviour, so this is a point that could be investigated further. 

An area of communities not covered well in the papers above is problems they have had with the online community they created. While there may have been none it is very usual for issues to occur that require moderation, though this may have been mitigated by strict rules set out by the university. Jiang et al. (2019) discuss problems with moderating communities on Discord, outlining problems such as hate speech and harassment. In their research they conducted interviews with Discord moderators discussing common challenges, and the best ways to combat them. They conclude that incidents over voice communication are especially hard to deal with, given there is no evidence beside potential witnesses and that this can lead to inaction or even false accusations between server members. The paper also highlights common issues moderators encounter, both from within the server’s community and outside of it. Server Rules are discussed at length both explicitly written down and some implicit, and how they are enforced and punishments given. Discord recommends adding server rules on creation of a new server, and the research here encourages the use of strict rules and a clear punishment system to keep users in line. However, strict rules and punishments may result in loss of members or engagement over time.

From the outside there are two main problems, phishing and raiding. Phishing is very common in the IT world, and on Discord normally stems from a new user joining a server and then sending everyone in the server a phishing message trying to gain personal information or access to an account. Raiding is when a group of people join a server and then start being extremely disruptive, such as joining voice channels and making loud noises or spamming text channels with harmful messages. These can be difficult to prevent, but removing the users from the server is possible depending on the size of the group. It is also possible to filter new users through a vetting process before giving access to the entire server, but this is only common among large servers.

**Privacy, Safety and Security on Similar platforms**
From looking at the existing research on forensics and community building, it appeared that there are some clear gaps when it came to academic research around user safety, security and privacy on Discord and that because the platform is rapidly growing while having increased trouble with cybercrime and harassment research in this area would be useful. To gain a better understanding of what to investigate in these areas, this literature review expanded to look at research on security, safety and privacy problems on similar platforms such as other VoIP, Instant Messaging and Social Media services. The purpose behind this was to find common trends and issues on these platforms, and see if any of the research findings could be applicable to Discord or would we worth investigating on the Discord platform. In particular to find out how these issues affected users, and what their experience and perceptions around them are.

*VoIP and Instant Messaging*
The first point of call when investigating research done on similar platforms was to look at VoIP, as this was Discord’s initial purpose. In 2010 Coulibaly and Liu published a paper investigating security on VoIP services. They emphasise the importance of security in these services and suggest some possible solutions to help make them more secure. Additionally, they look at several paths to attack VoIP including phishing, denial of service, and eavesdropping. Some of these are noted as problems in Discord’s transparency report discussed previously. One that isn’t mentioned is eavesdropping, and this in particular is very dangerous because once you join a Discord server you are able to stay in it and read the text channels to see all information posted there. This has huge potential for abuse. Another report that corroborates the importance of security and privacy on VoIP applications was done by Azafar, Choo and Liu (2016).  This investigation focussed on mobile applications, and Discord itself can also be used via a mobile app alongside its desktop and web browser clients. They looked more at the technical side and the encryption used for the communications, with services like Tango and WeChat.

Another place to look to gain insight is with Instant Messaging services. As previously discussed, Discord has become a home for different kinds of communities, and a space for people to collaborate. Team collaboration and its related social behaviours were investigated by Shen et al. (2011) with regard to Instant Messaging. They surveyed 482 students and found that for new or inexperienced users were likely to follow trends set by other users in how they use the platform and engage with its features. Applying this to look at Discord and its privacy and safety features can give insight into how new users to the platform will be more likely to interact with these settings. New users will be likely to use the same settings as their peers that already use the platform, which is problematic if existing users don’t perceive these settings to be important.

Cyberbullying and other harassment are prevalent on Discord and highlighted as some of the main reasons users get banned. This isn’t a new to these sorts of platforms and research has been done into how users of Instant Messaging services experience cyberbullying. Wolfsberg (2006) discusses how users can feel empowered by the anonymity of the internet and don’t think about how their actions can affect others, and this is coupled with a decrease in accountability. The report also discusses how authoritative bodies (which in the case of Discord would be the server owner or their appointed administrators) need to be willing to keep users in line, and suggests laying out a set of rules for users to follow. Some Discord servers have rules, but many do not and the enforcement of rules in the servers that do have them vary wildly. Looking at how users interact with admins and whether rules or sanctions are enforced would be a useful area of research.

*Social Media*
The next area to try and gain insight from is social media and platforms like Facebook, and what we can learn and apply to Discord from research done into privacy, security and safety issues on them. Facebook in particular has become infamous for problems with privacy and data handling on the platform, but it took very high-profile cases in the media to change public perceptions on masse. Looking at social media is very helpful to gain insights about user perceptions and concerns. Netchitailova (2012) interviewed users asking about the balance between concern for their privacy and the convenience of the platform compared to others. The research found that while many users had concern about privacy on the platform, the benefits and convenience of the platform outweighed them.  Srinivasan (2012) also discusses this and found that many social media users valued convenience over security and privacy on the platform. When looking at privacy on Discord one path of investigation could be to look at the convenience of the privacy settings available and whether users make use of them.

A survey conducted at Arizona State University found that there are two types of attacks to be wary of with data on social media platforms; identity disclosure, and attribute disclosure (Beigi and Liu 2020). Identity disclosure such as doxing has become well known on the internet, and is a reason for user and server bans highlighted in Discord’s transparency report. Whole servers dedicated to finding and sharing people’s personal information had to be deleted. Discord itself takes this incredibly seriously, but users should also be aware of the dangers of posting personal information online. Gritzalis et al. (2014) also discuss the dangers of personal information online and illustrate how it can be used for commercial or nefarious purposes with profiling and discrimination with examples of methods used on Twitter and YouTube. Investigating how users manage their data on Discord, and whether they have posted personal information about themselves on the platform is definitely worthwhile as these are very real dangers on the platform.

Looking further at research into user perceptions on social media, Zhao, Lampe and Ellison (2016) suggest that many people use a variety of communication methods across multiple platforms, while most research only looks at the platforms individually. While this bodes well for comparing practices between platforms the focus for their research is about what users are willing to share on each platform and their considerations when doing so. They found that: “people simultaneously consider ‘audience’ and ‘content’ when sharing”. This is an interesting idea to examine user perceptions on Discord with because some servers will have lots of people and strangers in, while a small personal server may only have a handful of friends you know and trust. Srinivasan (2012) found that many users shared personal information intended to only be seen by friends and family with little regard to how it could be accessed by other parties, and this can also be examined on discord in a similar way. 

Showing users information about these issues on social media does increase awareness and raise concerns Golbeck and Mauriello (2016) found, but that in general the participants in their research were under-informed. It is very likely that the same is true of Discord. Raising awareness of privacy and safety settings, dangers that exist and ways to mitigate them on these kind of platforms does work to effect perceptions; and many people are not fully aware of the threats that exist. This research into Discord will hopefully raise awareness and concerns about privacy, safety and security among participants and readers. As previously discussed, current users taking these issues more seriously will also make new users coming into the platform more likely to take them seriously too.

**Conclusion**
There isn’t a large amount of academic research on Discord itself, and as the platform grows, privacy, safety and security issues do too. Discord’s own transparency report highlights many of the problems in these areas that the platform and its users face, but little academic research has been done into how users experience and perceive these problems. This presents a large gap in research, which could be very useful for users of the platform or those wishing to use it to start or house communities. While there is not much existing research on Discord itself it is possible to draw on research from similar platforms to inform the research methodology and analysis for this report. 
