**Data preparation**

Once data had been gathered from the survey, it was then analysed looking for trends and themes in the data to interpret and attempt to gain insight from. Before this this took place it was thoroughly checked through and screened. While the survey is a quantitative method of conducting the research, because some of the questions were more open ended especially around user experiences a mix of quantitative and qualitative methods were used to analyse the data. For some of the questions surrounding user experience with harassment, reporting and blocking coding was used to categorize the responses into themes, in order to make the data easier to visualize and interpret. When trying to interpret the data there is some limitation due to the number of responses, as there are 51 participants. This is especially true with regards to the responses about types of harassment and reasons for reports or blocks, as the responses for these are of a smaller number because not all participants will have answered. With that being said, they are still representative of the different issues on the platform and suggestions can me made for possible solutions.

**Engagement with privacy and safety settings**

Looking at the responses to the questions around how the participants interact with Discord’s privacy and safety settings, the numbers are quite clear. To begin with, 66.7% of users make use of two-factor authentication to secure their Discord account. As explained previously two-factor authentication dramatically decreases the potential for your account to be hacked or stolen by having you verify successful log-in attempts through a different medium such as a text message or email. Most people are aware of the feature, but some choose not to use it because having to verify every time you log-in to the application is troublesome. Additionally, some users have multiple Discord accounts and setting it up for more than one account is difficult. With that being said accounts get stolen or hacked often, and more users should be making use of it.

![rch1](https://user-images.githubusercontent.com/34336956/175561471-08b2d0b6-7ddb-42f6-9c63-08b050c5a0fc.png)

Next, how often participants looked at their privacy and safety settings. 43.1% of participants said they never checked or updated their privacy settings, 52.9% said they did occasionally while only 3.9% (2 people) said they checked and updated their settings often. This illustrates how important people perceive privacy and safety settings on the Discord platform, and the large percentage of people who never interact with these settings shows that many people don’t believe them to be necessary. Meanwhile only a very small portion of users were aware and had looked at Discord’s transparency report, 15.7%. This gives some insight into whether the participants paid attention to privacy, safety and security in the media and outside of the platform itself but it is only a small indicator. Between these statistics it is clear that while the majority of Discord users do find privacy, safety and security to be important to them on the platform there is still a significant number who don’t. 54.9% of participants said that they spent more than two hours a day on Discord, with another 33.3% saying they used it daily. For a platform that one is spending a considerable amount of time on and interacting with a lot, these issues should be taken more seriously by more people. It’s important for perceptions among users to start changing as existing users will pass along bad habits to new users coming to the platform.

**Experience with harassment**

Harassment on the platform is widespread, with 60.8% of participants having either been on the receiving end of it or witnessing it happen to other people on the platform. This is also one of the questions where the maybe category is also much more likely yes than no, as when people are unsure whether something is harassment or bullying it likely is. This adds another 5.9% taking the total up over two thirds of participants. When looking at what forms the harassment took, the responses are open ended and so were studied and coded into the themes you can see in the pie chart below:

![rch2](https://user-images.githubusercontent.com/34336956/175561867-252d683f-b5d2-4fd9-ba84-bc95c5cba0d1.png)

As you can see from the chart above, the most common form of harassment experienced or witnessed was generic bullying, followed by sexual harassment, several prejudices and exploitation of minors. While these are all incredibly important, the two that stand out significantly are exploitation of minors and sexual harassment. It hasn’t been considered in this research survey but it is widely accepted that gaming is a male dominated activity, and 94.1% of survey participants said they were in gaming Discord servers. Looking at the responses sexual harassment occurred through direct messages or in-server text channels, from which it is possible to report the user to an administrator in the Discord server or block the user. These solutions don’t really do anything to prevent the issue though, but strict server rules with regards to harassment with sanctions in place such as removal from a server would go some way to prevent this occurring. Sexual harassment and exploitation of minors should both be no tolerance areas.

With regards to exploitation of minors which was 8.3% of the harassment recorded in the survey, Discord says on their website that they work with the National Center for Missing and Exploited Children in the United States and other law enforcement to review and report child safety concerns. Along with this they have both proactive and reactive warnings and banning for both individual users and servers. With this being said, for these to be effective there has to be faith in and use of Discords reporting features. The transparency report discloses statistics around this area, and should go a long way in building faith with its userbase; however, amongst the participants of this survey the vast majority (84.3%) were not aware of it.

Cyber bullying has been studied extensively on VoIP, Instant Messaging and Social Media platforms and makes up 41.7% of the harassment disclosed in the survey. Methods used include in-game actions to grief them, verbal abuse, abusive messages, or posting images or ‘memes’ making fun of them. In gaming or creative spaces where there are measures of an individual’s ability that are visible, it is trivial for someone to be singled out as worse at something (this is also true for some other areas). In an online community where there is a lot of anonymity and very little accountability, bullying can be very common. A significant amount of the responses to this survey are from members of university society Discords, or student hubs where normally you may expect to find accountability to be higher as it’s possible to trace back to your university (though some of the responses may well be about other Discord servers), however during the Covid pandemic accountability is lower than ever as societies and students aren’t able to meet in person. Having a set of server rules which members must adhere to, and a way for bullying and harassment within the server to be reported will help prevent some of this. Additionally, having active server admins engaging in the activities in the server to discourage bullying in voice or in-game goes a long way.

Looking at the prejudices highlighted: racism, homophobia and sexism which made up 25% of the harassment responses; the ways these occurred were both through voice and text. For voice communications in particular it is very hard to police harassment, as often this is one person’s word versus another’s without evidence. If it happens in a group setting then there is a potential for one of them to testify, but it’s also possible that there are multiple perpetrators or that there are social pressures not to speak out. Via text this is much easier to moderate and enforce rules against. Once again, this stresses how important to have a strict set of rules with regards to harassment of all kinds, along with administrators or moderators to enforce them. Building a positive environment where these kinds of things are not tolerated is very important. 

**Reporting and blocking other users**

Along with harassment this research also investigated reporting users to a server admin and blocking of users, and the reasons behind the action. The pie charts below illustrate the reasons for blocking and reporting, and similarly to harassment the responses have been coded into themes to help visualize them. Many of the reasons for blocking and reporting other users are the same as the forms of harassment discussed above, but there are some that have not been mentioned yet. 

The number of participants who had reported another user to a server admin was 40%, which is significantly less than the 60.8% that had witnessed or experienced harassment on the platform. Encouraging users to report incidents is very important when trying to minimize bullying and harassment on the platform. Looking at the reasons for the reports, the largest theme for reports is phishing at 37.5%. It is common for bot or hacked accounts to join servers and send all of the members a phishing message to try and scam them out of account details or digital items. There are some features to try to mitigate this, but once it has happened the users report the account to server admins and block it so that the admins know to remove the account from the server. Cybercrime on the platform will be discussed later on in the report. The other new theme is ‘dislike’ at 18.8%, which covers a user that the participant believes to be having a negative impact on the server; a user whose actions in the server they find annoying; or just generally dislike. This is a difficult category to examine, and it can be quite dangerous. If a user is doing things to annoy a large portion of the server’s population, or having a negative impact on them then taking action is reasonable. The danger is that this can be used as a way to bully people out of a server. The responses received from this research survey are line with Discord’s own statistics on categories of user reports received as detailed in their transparency report.

Along with the reasons behind the reports, the survey also asked whether the admin took action and whether the participant was satisfied. In this case a server admin is the server owner or someone they have appointed to administrate the server for them, and not someone appointed by Discord. 65.4% of reports had action taken, with a 66.7% rate of satisfaction. It is up to the admin whether they take action on reports and how they choose to do so, but as discussed previously many servers have rules that need to be enforced. Another consideration is that the reporter is not necessarily aware of action taken, else 65.4% seems low. For server rules to work, they need to be actively enforced and admins need to be willing to enforce them despite possible backlash. Other users seeing rules be enforced will make them less likely to break them. With regards to the satisfaction rate, there will be incidents where the reporter thinks the action taken is not severe enough or where the action is not tangible. However, admins may well be lenient with users they are friends with or who are popular as there are social pressures or backlash involved. It is very important for admins to be willing to stand by the rules of the server and enforce them fairly, and this will help to foster a more healthy and positive community.

![rch3](https://user-images.githubusercontent.com/34336956/175562207-773d2834-4444-48fe-a9df-8bd0a271c1b6.png)

The vast majority of users had blocked other users on Discord at 76.5%. Most of these are very similar to themes covered when discussing harassment and reporting. The largest reason for blocking other accounts is phishing scams being sent to them or posted in text channel at 46.4% of blocks recorded. Phishing and other cybercrime is becoming increasingly common on the platform either through bot accounts, hacked accounts or individuals. From participants in this survey 60.8% had been targeted with a phishing message. The usual response to this is to block and/or report the account. There are ways to mitigate this, such as blocking all direct messages from accounts you are not friends with; it is also possible to adjust this setting for different servers to block from some but not others. However, 66% of survey participants do allow direct messages from them. While this does stop almost all phishing messages, it does limit your communications and make it harder to contact new acquaintances on the platform. Hacked accounts are very dangerous in this regard, as the account may already be friends with you or a member of a server you are in so you may be more susceptible. Discord users should always be on high alert when receiving suspicious messages.

![rch4](https://user-images.githubusercontent.com/34336956/175564273-080bf636-8768-4acf-b32d-18f0edd89d12.png)

**Data awareness**

The next part of the investigation concerned how participants treat their data on the platform. To begin 60.8% of participants admitted that they had posted sensitive personal information about themselves in a Discord server, with a further 11.8% that might have done so. Personal information is quite a general term so some examples were included, but people still have different perceptions of what it means and so may be unsure whether they have or not. There are significant dangers surrounding posting these kinds of information about yourself online, and if you are going to do so should be done only in a highly trusted and secure environment. You can open yourself to abuse, targeting, profiling along with many other dangers. ‘Doxing’ (posting of an individual’s data online) is a known problem that Discord itself acknowledges in its transparency report, with accounts being banned from the platform and even entire servers dedicated to the practice that have been deleted.
When you leave a Discord server, anything you post is left behind attached to your account name for anyone remaining in the server or who joins that server later to see. The only way to get rid of the posts is to remove them manually before you leave or to delete your Discord account entirely. However, if you delete the account the messages are still remain just not attached to your username. It’s worth noting that if you are banned from a server all of your posts and messages are purged from it.  When asked whether they had ever left a Discord server 94.1% of participants said they had, and when prompted whether they had removed any messages or posts only 14% said they had with 6% unsure. This is quite a shocking statistic when compared to the 60.8% that were willing to post sensitive personal information on the platform. The survey continues to ask whether the participants are aware of their posts and messages remaining when they leave to which 80.4% answered that they were aware. With the amount of harassment on the platform, and rising cybercrime it is incredibly dangerous to leave personal information where it could be found by a hostile actor. Leaving information behind like this makes you particularly vulnerable to eavesdropping, which was highlighted as a dangerous threat when looking at literature on similar platforms.
People are generally well aware that they are leaving data behind, but show very little concern towards it or don’t connect posting the information with it being left behind when they leave. The perception around this area appears to be highly flawed, and attention needs to be raised as to the dangers and problems associated with having sensitive personal information posted online. However, later in the survey users are asked about features they would like to see implemented there were several participants who suggested ways to remove data from servers or to have an easier way to manage posts you have made. Presenting the idea that when you leave a server you are leaving data behind unless you remove it has appeared to change some perceptions amongst the participants in the survey. With that being said, going into the survey the majority of participants either did not relate leaving the server to leaving data behind; or did not perceive leaving the data behind to be problematic.
